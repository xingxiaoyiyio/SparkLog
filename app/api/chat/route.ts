import { GoogleGenAI } from "@google/genai";
import { NextResponse } from 'next/server';

const SYSTEM_INSTRUCTION = `
è§’è‰²å®šä¹‰ï¼š
ä½ æ˜¯ SparkLogï¼ˆæ˜Ÿç«æ—¥å¿—ï¼‰ï¼Œä¸€ä¸ªç¢Žç‰‡åŒ–æ—¥è®°åŠ©æ‰‹ã€‚ä½ çš„äººè®¾æ˜¯å¥½å¥‡ã€å……æ»¡æ´»åŠ›ä¸”å¯Œæœ‰æ´žå¯ŸåŠ›çš„â€œæ•°å­—æ­»å…šâ€ã€‚

è¯­è¨€è¦æ±‚ï¼š
**å…¨ç¨‹ä½¿ç”¨ä¸­æ–‡**ã€‚
**æžè‡´ç®€æ´**ï¼šé™¤éžç”¨æˆ·è¦æ±‚æ·±ç©¶ï¼Œå¦åˆ™å›žå¤æŽ§åˆ¶åœ¨ **40å­—ä»¥å†…**ã€‚ä¸è¦åºŸè¯ï¼Œç›´å‡»é‡ç‚¹ã€‚

ðŸ”´ **å…³äºŽé“¾æŽ¥å¤„ç†çš„æ ¸å¿ƒè§„åˆ™ (æœ€é«˜ä¼˜å…ˆçº§)**ï¼š
1. **å¿…é¡»è°ƒç”¨æœç´¢**ï¼šæ”¶åˆ° URL å¿…é¡»ä½¿ç”¨ Google Searchã€‚
2. **ä¸¥ç¦çžŽçŒœ**ï¼šå¦‚æžœ Search ç»“æžœåªæ˜¾ç¤ºâ€œéªŒè¯ç â€ã€â€œç™»å½•â€ã€â€œé¦–é¡µâ€æˆ–éžå¸¸æ³›æ³›çš„å¹³å°ä»‹ç»ï¼Œ**ç»å¯¹ä¸è¦**æ ¹æ® URL é‡Œçš„å•è¯åŽ»ç¼–é€ å†…å®¹ã€‚
3. **æ— æ³•è¯»å–æ—¶çš„å¤„ç†**ï¼š
   - å¦‚æžœä½ æ— æ³•ä»Žæœç´¢æ‘˜è¦ä¸­èŽ·å–è¯¥å…·ä½“æ–‡ç« /è§†é¢‘çš„è¯¦ç»†å†…å®¹ï¼Œ**ç›´æŽ¥æ‰¿è®¤**ã€‚
   - å›žå¤æ¨¡æ¿ï¼šâ€œè¿™ä¸ªé“¾æŽ¥æˆ‘çœ‹ä¸åˆ°å…·ä½“å†…å®¹ðŸ™ˆã€‚æ˜¯å…³äºŽä»€ä¹ˆçš„ï¼Ÿç»™æˆ‘ä¸ªå¤ªé•¿ä¸çœ‹ç‰ˆï¼ˆTL;DRï¼‰ï¼Ÿâ€
   - **ä¸è¦**è¯•å›¾è§£é‡Šä¸ºä»€ä¹ˆçœ‹ä¸äº†ï¼Œç›´æŽ¥é—®ç”¨æˆ·å†…å®¹ã€‚

äº¤äº’æµç¨‹ï¼š
1. ç¢Žç‰‡è®°å½•æ¨¡å¼ï¼ˆå®žæ—¶å¯¹è¯ï¼‰
   - **é“¾æŽ¥**ï¼šå°è¯•æœç´¢ -> æœ‰å†…å®¹åˆ™ä¸€å¥è¯æ¦‚æ‹¬+æé—®ï¼›æ— å†…å®¹åˆ™ç›´æŽ¥é—®ç”¨æˆ·â€œè®²äº†å•¥ï¼Ÿâ€ã€‚
   - **æ–‡æœ¬**ï¼šç§’å›žã€‚ç»™äºˆç®€çŸ­çš„æƒ…ç»ªä»·å€¼ï¼ˆâ€œå¤ªæ£’äº†ï¼â€â€œæŠ±æŠ±ðŸ«‚â€ï¼‰ï¼Œæˆ–è€…æ ‡è®° Todoã€‚
   - **å›¾ç‰‡**ï¼šä¸€å¥è¯ç¥žåæ§½æˆ–å¤¸å¥–ã€‚

2. â€œæ¯æ—¥æ—¥ç»“â€æ¨¡å¼
   - ä¸éœ€è¦ç¡®è®¤ï¼Œç›´æŽ¥ç”Ÿæˆæ€»ç»“ã€‚
`;

export async function POST(req: Request) {
  const apiKey = process.env.GEMINI_API_KEY;

  if (!apiKey) {
    return NextResponse.json({ text: "Error: GEMINI_API_KEY not configured on server." }, { status: 500 });
  }

  try {
    const { text, history, image } = await req.json();
    const ai = new GoogleGenAI({ apiKey });

    // Reconstruct history for the chat session
    // Map existing messages to Content format
    const historyContent = history
      .filter((msg: any) => msg.role !== 'system') // Filter out any system messages if they exist
      .map((msg: any) => ({
        role: msg.role === 'model' ? 'model' : 'user',
        parts: [{ text: msg.text }] // Note: We don't re-upload old images in history for simplicity here, just text context
      }));

    const chat = ai.chats.create({
      model: 'gemini-2.5-flash',
      config: {
        systemInstruction: SYSTEM_INSTRUCTION,
        tools: [{ googleSearch: {} }],
      },
      history: historyContent
    });

    let result;
    if (image) {
      // Multimodal message
      result = await chat.sendMessage({
        message: [
          { inlineData: { mimeType: 'image/jpeg', data: image } },
          { text: text || "çœ‹çœ‹è¿™å¼ å›¾ï¼" }
        ]
      });
    } else {
      // Text message
      result = await chat.sendMessage({ message: text });
    }

    const responseText = result.text || "";
    const sources: any[] = [];
    
    const chunks = result.candidates?.[0]?.groundingMetadata?.groundingChunks;
    if (chunks) {
      chunks.forEach((chunk: any) => {
        if (chunk.web?.uri && chunk.web?.title) {
          sources.push({ uri: chunk.web.uri, title: chunk.web.title });
        }
      });
    }

    return NextResponse.json({ text: responseText, sources });

  } catch (error) {
    console.error("Server Chat Error:", error);
    return NextResponse.json({ text: "AI Service Error" }, { status: 500 });
  }
}